% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/di-fit.R
\name{apd_di}
\alias{apd_di}
\alias{apd_di.default}
\alias{apd_di.data.frame}
\alias{apd_di.matrix}
\alias{apd_di.formula}
\alias{apd_di.recipe}
\title{Fit a \code{apd_di}}
\usage{
apd_di(x, ...)

\method{apd_di}{default}(x, ...)

\method{apd_di}{data.frame}(x, y = NULL, importance, ...)

\method{apd_di}{matrix}(x, y = NULL, importance, ...)

\method{apd_di}{formula}(formula, data, validation = NULL, importance, ...)

\method{apd_di}{recipe}(x, data, validation = NULL, importance, ...)
}
\arguments{
\item{x}{Depending on the context:
\itemize{
\item A \strong{data frame} of predictors used to fit your model.
\item A \strong{matrix} of predictors used to fit your model.
\item A \strong{recipe} specifying a set of preprocessing steps
created from \code{\link[recipes:recipe]{recipes::recipe()}}.
}}

\item{...}{Not currently used, but required for extensibility.}

\item{y, validation}{A data frame or matrix containing the data used to
validate your model. This should be the same data as used to calculate all
model accuracy metrics.

If this argument is \code{NULL}, then this function will use the training data
(from \code{x} or \code{data}) to calculate within-sample distances.
This may result in the area of applicability threshold being set too high,
with the result that too many points are classed as "inside" the area of
applicability.}

\item{importance}{A data.frame with two columns: \code{Variable}, containing
the names of each variable in the training and validation data, and
\code{Importance}, containing the (raw or scaled) feature importance for each
variable.}

\item{formula}{A formula specifying the predictor terms on the right-hand
side.}

\item{data}{When a \strong{recipe} or \strong{formula} is used, \code{data} is specified as:
\itemize{
\item A \strong{data frame} containing the predictors used to fit your model.
}}
}
\value{
A \code{apd_di} object.
}
\description{
\code{apd_di()} fits a model.
}
\details{
This function calculates the "area of applicability" of a model, as
introduced by Meyer and Pebesma (2021). While the initial paper introducing
this method focused on spatial models, there is nothing inherently spatial
about the method; it can be used with any type of data.

Predictions made on points "inside" the area of applicability should be as
accurate as predictions made on the data provided to \code{y} or \code{validation}.
That means that generally \code{y} or \code{validation} should be your final hold-out
set, or the assessment set of a cross-validation fold, so that predictions
on points inside the area of applicability are accurately described by your
reported model metrics.

The \code{importance} argument is structured to work with objects returned by the
vip package, using functions such as \link[vip:vi_permute]{vip::vi_permute}.
}
\examples{
\dontshow{if (rlang::is_installed("vip")) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
library(vip)
train <- gen_friedman(1000, seed = 101)  # ?vip::gen_friedman
test <- train[701:1000, ]
train <- train[1:700, ]
pp <- stats::ppr(y ~ ., data = train, nterms = 11)
importance <- vi_permute(
  pp,
  target = "y",
  metric = "rsquared",
  pred_wrapper = predict
)

apd_di(y ~ ., train, test, importance = importance)
\dontshow{\}) # examplesIf}
}
\references{
H. Meyer and E. Pebesma. 2021. "Predicting into unknown space? Estimating
the area of applicability of spatial prediction models," Methods in Ecology
and Evolution 12(9), pp 1620 - 1633, doi: 10.1111/2041-210X.13650.
}
